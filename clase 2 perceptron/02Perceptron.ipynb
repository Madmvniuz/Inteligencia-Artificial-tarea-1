{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "#Instalando nuevas librerias\n",
    "#No correr si no es necesario\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]\n",
      "Numpy version: 1.22.4\n",
      "Pandas version: 1.4.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version:\",sys.version)\n",
    "print(\"Numpy version:\",np.__version__)\n",
    "print(\"Pandas version:\",pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la data normal es esta wea       ID  Edad Sexo NivelEducacion EstadoCivil NivelSocEco  HorasLogeadas  \\\n",
      "0      1    32    m             un           s        c3c4       151.1525   \n",
      "1      2    24    m             em           s        c3c4        71.1800   \n",
      "2      3    29    m             em           c        c3c4       120.5600   \n",
      "3      4    48    f             em           c           e        90.8500   \n",
      "4      5    25    m             un           s        c3c4       190.1800   \n",
      "..   ...   ...  ...            ...         ...         ...            ...   \n",
      "655  656    50    f             em           c           e       193.7820   \n",
      "656  657    28    f             un           s        abc1       193.3200   \n",
      "657  658    29    m             un           s          c2       120.8200   \n",
      "658  659    28    f             ts           s        c3c4       164.6262   \n",
      "659  660    33    m             ts           s           e       121.2960   \n",
      "\n",
      "     HorasHabladas  ContactosEfectivosPromedio  RegistrosTerminados  \\\n",
      "0          45.8525                  192.250000           591.750000   \n",
      "1          24.7600                    1.000000           501.000000   \n",
      "2          49.4500                  156.000000           993.000000   \n",
      "3          28.8500                  442.000000           569.000000   \n",
      "4          41.1600                    0.000000             0.000000   \n",
      "..             ...                         ...                  ...   \n",
      "655        90.1750                  376.500000           908.000000   \n",
      "656        71.5200                  390.000000           687.500000   \n",
      "657        39.1300                   85.666667           471.666667   \n",
      "658        51.7097                  428.600000           494.600000   \n",
      "659        35.7900                  147.200000           404.000000   \n",
      "\n",
      "    ProdMayorUbral  ProdPromAprobada  \n",
      "0               si          334750.0  \n",
      "1               no           35587.0  \n",
      "2               si          312750.0  \n",
      "3               no           15131.0  \n",
      "4               si          531400.0  \n",
      "..             ...               ...  \n",
      "655             si          335850.0  \n",
      "656             si          770000.0  \n",
      "657             no          154250.0  \n",
      "658             si          258775.5  \n",
      "659             si          208876.0  \n",
      "\n",
      "[660 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "#Loading and splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "data=pd.read_csv('data\\CallCenterData.csv', delimiter = ';')\n",
    "print('la data normal es esta wea', data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la data final q son solo las variables numericas son              Edad  HorasLogeadas  HorasHabladas  ContactosEfectivosPromedio  \\\n",
      "count  660.000000     660.000000     660.000000                  660.000000   \n",
      "mean    32.034848     117.025260      41.113746                  192.477960   \n",
      "std      8.970209      53.348341      25.310637                  146.711340   \n",
      "min     19.000000       0.170000       0.013333                    0.000000   \n",
      "25%     26.000000      79.197125      21.767312                   84.625000   \n",
      "50%     29.500000     122.679417      37.665000                  181.000000   \n",
      "75%     36.000000     160.650250      57.709000                  270.558333   \n",
      "max     65.000000     258.400000     122.182500                 1216.000000   \n",
      "\n",
      "       RegistrosTerminados  ProdPromAprobada  \n",
      "count           660.000000      6.600000e+02  \n",
      "mean            467.773235      1.985324e+05  \n",
      "std             312.863798      1.903580e+05  \n",
      "min               0.000000      0.000000e+00  \n",
      "25%             231.107143      3.722875e+04  \n",
      "50%             440.500000      1.450363e+05  \n",
      "75%             645.812500      3.125625e+05  \n",
      "max            1890.250000      1.132250e+06  \n",
      "\n",
      "Verificando el balance de las clases 309\n"
     ]
    }
   ],
   "source": [
    "#Obteniendo solo las variables numéricas\n",
    "finalData=data.iloc[:,[1,6,7,8,9,10,11]]\n",
    "print('la data final q son solo las variables numericas son', finalData.describe())\n",
    "\n",
    "print(\"\\nVerificando el balance de las clases\", np.sum(finalData.iloc[:,5]==\"si\"))\n",
    "\n",
    "trainData, testData = train_test_split(finalData, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de la clase sklearn\n",
    "La mayoría de los modelos de sklearn corresponden a “objetos” de cierta “clase” con propiedades y funciones específicas. En términos prácticos solo se necesita crear una caja mágica que contiene todo lo necesario para aplicar y analizar los modelos.\n",
    "* from sklearn.xxx import modeloDeseado => Importación del modelo\n",
    "* nuevoModelo = modeloDeseado() => Creación del modelo\n",
    "* nuevoModelo.function() => Aplicar alguna función\n",
    "* nuevoModelo.attribute => Ver los valores de un atributo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n",
    "\n",
    "\n",
    "La clase Perceptron de sklearn linear_model nos permite implementar el perceptron en su forma más sencilla.\n",
    "\n",
    "<font color=\"white\">\n",
    "Perceptron(*, penalty=None, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, eta0=1.0, n_jobs=None, random_state=0, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False)</font>\n",
    "\n",
    "Por ahora, solo nos vamos a enfocar en unos pocos parámetros.<br>\n",
    "<font color=\"white\">Perceptron(*, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True)</font>\n",
    "\n",
    "Parámetros:\n",
    "* *: matriz con los datos\n",
    "* fit_intercept: neurona para modelar el sesgo.\n",
    "* max_iter: máximo número de iteraciones es decir el número de épocas.\n",
    "* tol: tolerancia del error, sera None debido a que estamos implementando el perceptrón básico.\n",
    "* shuffle: Si los datos debieran ser barajados después de cada época.\n",
    "\n",
    "Como se puede observar, esta versión de sklearn es bastante limitada, pero de igual manera la veremos.\n",
    "\n",
    "Funciones:\n",
    "* fit(X,y): entrena el modelo usando la matriz de datos X y la variable binaria y.\n",
    "* predict(X): Predice el valor de X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(tol=None)\n",
      "Perceptron(tol=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron \n",
    "#Perceptron es una clase con múltiples parámetros, atributos y funciones.\n",
    "#Para aplicar Perceptron es necesario crear el objeto y luego aplicarto\n",
    "\n",
    "#Creando un objeto de Perceptron con las condiciones iniciales\n",
    "#Como se puede observar, no estamos definiendo nada del modelo\n",
    "red = Perceptron(tol=None)\n",
    "print(red)\n",
    "#El objeto ha sido creado\n",
    "\n",
    "#Entrenando el modelo con variables numéricas\n",
    "red.fit(trainData.iloc[:,[0,1,3,4]], trainData.iloc[:,5]==\"si\")\n",
    "print(red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caracteristicas del modelo entrenado\n",
    "Una vez entrenado el modelo, existen nuevas características que podemos observar (atributos)<br>\n",
    "Atributos:\n",
    "* coef_: pesos asociados a cada variable.\n",
    "* intercept_: Intercepto del modelo.\n",
    "\n",
    "Funciones:\n",
    "* fit(X,y): entrena el modelo usando la matriz de datos X y la variable binaria y.\n",
    "* predict(X): Predice el valor y usando los valores X.\n",
    "* decision_function(X): Devuelve el valor calculada en la neurona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficiente para cada variable:  [[-13569.           2976.79113569    777.7293937    -170.71502439]]\n",
      "Coeficiente del intercepto:  [-17733.]\n"
     ]
    }
   ],
   "source": [
    "#Como el modelo ha sido entrenado podemos ver los pesos\n",
    "print(\"Coeficiente para cada variable: \",red.coef_)\n",
    "print(\"Coeficiente del intercepto: \",red.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recordar que el Perceptron solo múltiplica los weights por los valores de entrada\n",
    "print(\"suma de la Neurona\",red.decision_function(testData.iloc[0:1,[0,1,3,4]].values))\n",
    "print(\"suma manual\",np.sum(testData.iloc[0,[0,1,3,4]].values*red.coef_)+red.intercept_)\n",
    "print(\"probabilidad\",1/(1+np.exp(-red.decision_function(testData.iloc[0:1,[0,1,3,4]].values))))\n",
    "print(\"Clase\",red.predict(testData.iloc[0:1,[0,1,3,4]].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recordemos k-fold cross-validation\n",
    "\n",
    "El objeto KFold de sklearn.model_selection permite separar los datos en K-fold. A pesar de haber otras funciones que también permiten aplicar y evaluar k-fold cross validation en forma sencilla, esta separación/evaluación no se podría usar con otros modelos que no fueran de sklearn.<br><br>\n",
    "\n",
    "La función no separa los datos, simplemente retorna los índices de cada fold, la separación se hace de forma posterior.<br>\n",
    "KFold(n_splits=5, shuffle=False, random_state=None)<br>\n",
    "Parámetros\n",
    "* n_splits: número de folds a utilizar\n",
    "* random_state: valor entero, permite replicar un experimento al setear la semilla de los números aleatorios.\n",
    "* shuffle: booleano, en caso de verdadero los datos se \"barajan\" antes de ser separados.<br><br>\n",
    "\n",
    "Métodos\n",
    "* split(X[, y, groups]): Genera los índices para separar los datos de entrenamiento y test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analizando el error del Perceptron\n",
    "#Creando los objetos con sus características \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics as mt\n",
    "numFolds=10\n",
    "\n",
    "kf = KFold(n_splits=numFolds,shuffle=True)\n",
    "\n",
    "allAccTrain=np.zeros((numFolds,1))\n",
    "allAccTest=np.zeros((numFolds,1))\n",
    "\n",
    "index=0\n",
    "for train_index, test_index in kf.split(finalData.iloc[:,[0,1,3,4]]):\n",
    "    #Perceptron(*, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0)\n",
    "    model = Perceptron(tol=None,max_iter=500,fit_intercept=True)\n",
    "    model=model.fit(finalData.iloc[train_index,[0,1,3,4]],finalData.iloc[train_index,5])\n",
    "    prediccion=model.predict(finalData.iloc[train_index,[0,1,3,4]])\n",
    "    allAccTrain[index]=mt.accuracy_score(finalData.iloc[train_index,5],prediccion)\n",
    "    prediccion=model.predict(finalData.iloc[test_index,[0,1,3,4]])\n",
    "    allAccTest[index]=mt.accuracy_score(finalData.iloc[test_index,5],prediccion)\n",
    "    index+=1\n",
    "print(\"Average ACC train error: \",allAccTrain.mean(),\"+-\",allAccTrain.std())\n",
    "print(\"Average ACC test error: \",allAccTest.mean(),\"+-\",allAccTest.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizando el output de un perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargando el dataset\n",
    "from sklearn.datasets import make_moons\n",
    "data=make_moons(n_samples=1000,noise=0.3)\n",
    "\n",
    "moonData=pd.DataFrame(data[0],columns=['X1','X2'])\n",
    "moonData['Class']=data[1]\n",
    "moonData['Fill']=0\n",
    "moonData.loc[moonData[\"Class\"]==0,\"Fill\"]=\"Red\"\n",
    "moonData.loc[moonData[\"Class\"]==1,\"Fill\"]=\"Blue\"\n",
    "\n",
    "ggplot(moonData)+aes(x=\"X1\",y=\"X2\",color=\"factor(Class)\")+geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creando y entrenando el dataset\n",
    "model = Perceptron(tol=None,max_iter=50,fit_intercept=True)\n",
    "model=model.fit(moonData.iloc[:,0:2],moonData.loc[:,\"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generando la grilla para la visualización\n",
    "x = np.arange(min(moonData.X1),max(moonData.X1),0.2)\n",
    "y = np.arange(min(moonData.X2),max(moonData.X2),0.2)\n",
    "temp = np.meshgrid(x, y)\n",
    "dataTest=pd.DataFrame(temp[0].flatten())\n",
    "dataTest.insert(1,\"yy\",temp[1].flatten())\n",
    "dataTest\n",
    "output=model.decision_function(dataTest)\n",
    "output=1/(1+np.exp(-output))\n",
    "\n",
    "#Creando el dataframe para graficar\n",
    "from plotnine import *\n",
    "df = pd.DataFrame(dataTest)\n",
    "df.insert(0,\"Class\",output)\n",
    "df.columns=['Class','X1','X2']\n",
    "df.Class=1-df.Class\n",
    "df.insert(3, \"Class2\", pd.qcut(df.Class, q=7, labels=False, precision=0))\n",
    "output2=(((output)*255).astype(\"int\"))\n",
    "df.insert(4, \"ClassOutput\", \"0\")\n",
    "for i in range(df.shape[0]):\n",
    "    df.ClassOutput[i]='#%02x%02x%02x' % (255-output2[i],0,output2[i])\n",
    "df\n",
    "\n",
    "#Generating the plot with ggplot/plotnine\n",
    "blankDF = pd.DataFrame(columns=[\"\"])\n",
    "pp=(ggplot(blankDF)+theme_void()+\n",
    "  geom_tile(aes(x=df.X1.values,y=df.X2.values),alpha=0.7,fill=df.ClassOutput.values)+  \n",
    "  geom_point(aes(x=moonData.X1.values,y=moonData.X2.values),show_legend = False,color=\"black\",fill=moonData.Fill.values)\n",
    ")\n",
    "pp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo 2, dataset de donut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creando el Doughnut dataset \n",
    "from sklearn.datasets import make_circles\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "samples, labels = make_circles(n_samples=1000, factor=.3, noise=.05)\n",
    "data=pd.DataFrame(samples)\n",
    "data.columns=['X1','X2']\n",
    "data.insert(2, \"Class\",labels)\n",
    "data.insert(3, \"Fill\",labels)\n",
    "data.loc[data.Class==1,'Fill']=\"Red\"\n",
    "data.loc[data.Class==0,'Fill']=\"Blue\"\n",
    "ggplot(data)+aes(x='X1',y='X2',color=\"factor(Class)\")+geom_point(show_legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creando y entrenando el dataset\n",
    "model = Perceptron(tol=None,max_iter=100,fit_intercept=True)\n",
    "model=model.fit(data.iloc[:,0:2],data.loc[:,\"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creando la grilla\n",
    "import numpy as np\n",
    "x = np.arange(-1.5, 1.5, 0.05)\n",
    "y = np.arange(-1.5, 1.5, 0.05)\n",
    "temp = np.meshgrid(x, y)\n",
    "dataTest=pd.DataFrame(temp[0].flatten())\n",
    "dataTest.insert(1,\"yy\",temp[1].flatten())\n",
    "output=model.decision_function(dataTest)\n",
    "output=1/(1+np.exp(-output))\n",
    "\n",
    "#Creating the data Frame to plot\n",
    "from plotnine import *\n",
    "df = pd.DataFrame(dataTest)\n",
    "df.insert(2, \"ClassOutput\", 1-output)\n",
    "df.columns=['X1','X2','Class']\n",
    "df.insert(2, \"Class2\", pd.qcut(df.Class, q=7, labels=False, precision=0))\n",
    "output2=(((1-output)*255).astype(\"int\"))\n",
    "df.insert(3, \"ClassOutput\", \"0\")\n",
    "for i in range(df.shape[0]):\n",
    "    df.ClassOutput[i]='#%02x%02x%02x' % (255-output2[i],0,output2[i])\n",
    "\n",
    "#Generating the plot with ggplot/plotnine\n",
    "blankDF = pd.DataFrame(columns=[\"\"])\n",
    "pp=(ggplot(blankDF)+theme_void()+\n",
    "  geom_tile(aes(x=df.X1.values,y=df.X2.values),alpha=0.7,show_legend=False,fill=df.ClassOutput.values)+    \n",
    "  geom_point(aes(x=data.X1.values,y=data.X2.values),show_legend = False,color=\"black\",fill=data.Fill.values)+\n",
    "  scale_x_continuous(limits = [-1.5,1.5])+scale_y_continuous(limits = [-1.5,1.5])\n",
    ")\n",
    "pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codificando variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and splitting the data\n",
    "data=pd.read_csv('breast-cancer.csv', delimiter = ',')\n",
    "# 0. Class: no-recurrence-events, recurrence-events \n",
    "# 1. age: 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, 70-79, 80-89, 90-99. \n",
    "# 2. menopause: lt40, ge40, premeno. \n",
    "# 3. tumor-size: 0-4, 5-9, 10-14, 15-19, 20-24, 25-29, 30-34, 35-39, 40-44, 45-49, 50-54, 55-59. \n",
    "# 4. inv-nodes: 0-2, 3-5, 6-8, 9-11, 12-14, 15-17, 18-20, 21-23, 24-26, 27-29, 30-32, 33-35, 36-39. \n",
    "# 5. node-caps: yes, no. \n",
    "# 6. deg-malig: 1, 2, 3. \n",
    "# 7. breast: left, right. \n",
    "# 8. breast-quad: left-up, left-low, right-up, right-low, central. \n",
    "# 9. irradiat: yes, no.\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables 1,3,4,5,6,7,9 must be numerical encoded\n",
    "variables=[1,3,4,5,6,7,9]\n",
    "for i in variables:\n",
    "    #transforming the data to categorical\n",
    "    data.iloc[:,i]=pd.Categorical(data.iloc[:,i])\n",
    "    #transforming categorical values to numbers (starting from 0)\n",
    "    data.iloc[:,i]=data.iloc[:,i].cat.codes\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables 2 and 8 must be one-hot encoded\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "tempDF = pd.DataFrame() #Empty dataframe\n",
    "tempDF = tempDF.fillna(0)\n",
    "\n",
    "#encoding each variable and generating a new data frame\n",
    "variables=[2,8]\n",
    "for i in variables:\n",
    "    #transforming the data to categorical\n",
    "    data.iloc[:,i]=pd.Categorical(data.iloc[:,i])\n",
    "    #transforming categorical values to numbers (starting from 0)    \n",
    "    data.iloc[:,i]=data.iloc[:,i].cat.codes\n",
    "    \n",
    "    #one-hot encoding by KERAS\n",
    "    #transforming the numerical values to one-hot encoding. \n",
    "    #Note the values must start from 0, otherwise more variables will be added.\n",
    "    temp=pd.DataFrame(to_categorical(data.iloc[:,i]))\n",
    "    temp.columns = [str(data.columns[i]) + str(col) for col in temp.columns]\n",
    "    tempDF=pd.concat([tempDF,temp], axis=1)\n",
    "\n",
    "tempDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining the one-hot encoded dataset\n",
    "names=data.columns[variables]\n",
    "for i in names:\n",
    "    data = data.drop(i, 1)\n",
    "data=pd.concat([data,tempDF], axis=1)\n",
    "print(data.head(3))\n",
    "print(data[\"Class\"].describe())\n",
    "finalData=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analizando el error del Perceptron\n",
    "#Creando los objetos con sus características \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics as mt\n",
    "numFolds=10\n",
    "\n",
    "kf = KFold(n_splits=numFolds,shuffle=True)\n",
    "\n",
    "allAccTrain=np.zeros((numFolds,1))\n",
    "allAccTest=np.zeros((numFolds,1))\n",
    "allF1Train=np.zeros((numFolds,1))\n",
    "allF1Test=np.zeros((numFolds,1))\n",
    "\n",
    "\n",
    "index=0\n",
    "for train_index, test_index in kf.split(finalData.iloc[:,[0,1,3,4]]):\n",
    "    #Perceptron(*, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0)\n",
    "    model = Perceptron(tol=None,max_iter=500,fit_intercept=True)\n",
    "    model=model.fit(finalData.iloc[train_index,1:],finalData.iloc[train_index,0])\n",
    "    prediccion=model.predict(finalData.iloc[train_index,1:])\n",
    "    allAccTrain[index]=mt.accuracy_score(finalData.iloc[train_index,0],prediccion)\n",
    "    allF1Train[index]=mt.f1_score(finalData.iloc[train_index,0]=='recurrence-events',prediccion=='recurrence-events')\n",
    "    prediccion=model.predict(finalData.iloc[test_index,1:])\n",
    "    allAccTest[index]=mt.accuracy_score(finalData.iloc[test_index,0],prediccion)\n",
    "    allF1Test[index]=mt.f1_score(finalData.iloc[test_index,0]=='recurrence-events',prediccion=='recurrence-events')\n",
    "    index+=1\n",
    "print(\"Average ACC train error: \",allAccTrain.mean(),\"+-\",allAccTrain.std())\n",
    "print(\"Average F1 train error: \",allF1Train.mean(),\"+-\",allF1Train.std())\n",
    "print(\"Average ACC test error: \",allAccTest.mean(),\"+-\",allAccTest.std())\n",
    "print(\"Average F1 test error: \",allF1Test.mean(),\"+-\",allF1Test.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viendo la cantidad de pesos del modelo\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "ce9167334efd97c5211d8924556d23bacc4aa06d7638842b4b7313cc4f840c3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
